{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1 — The birthday paradox\n",
    "\n",
    "Suppose you're in a room with 22 other people. What is the chance that any pair of people in the room have the same birthday? The answer will likely surprise you — it's much greater than most people think.\n",
    "\n",
    "In this exercise we'll use simulations to analyze this problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before getting to the simulations, let's consider the analytical probability (that is, the theoretical probability we can calculate.) As [Wikipedia explains](https://en.wikipedia.org/wiki/Birthday_problem#Calculating_the_probability), we want to calculate $p(n)$, the probability that at least two people in a room of $n$ people have the same birthday, but it turns out to be much easier to calculate ${\\bar {p}}(n) = 1-p(n)$, the probability that *no* two people in the room have the same birthday (that is, the complement).\n",
    "\n",
    "For example, with three people in a room, the probability that none of them have the same birthday is $$\\bar{p}(3) = 1 \\times \\left(1-{\\frac {1}{365}}\\right) \\times \\left(1-{\\frac {2}{365}}\\right).$$ This follows from the fact that to require no matching birthdays we can allow the first person to have any birthday at all, while the second person can have any birthday *except* the one that the first person has, and the third person can have any birthday except either of the first two.\n",
    "\n",
    "Generalizing to $n$ people, the probability is given by\n",
    "\n",
    "$${\\displaystyle {\\begin{aligned}{\\bar {p}}(n)&=1\\times \\left(1-{\\frac {1}{365}}\\right)\\times \\left(1-{\\frac {2}{365}}\\right)\\times \\cdots \\times \\left(1-{\\frac {n-1}{365}}\\right)\\\\&={\\frac {365\\times 364\\times \\cdots \\times (365-n+1)}{365^{n}}}\\\\&={\\frac {365!}{365^{n}(365-n)!}}={\\frac {n!\\cdot {\\binom {365}{n}}}{365^{n}}}={\\frac {_{365}P_{n}}{365^{n}},}\\end{aligned}}}$$\n",
    "where ${_{k}P_{n}}$ denotes the permutation function. (To get the second line, multiply every term by $\\frac{365}{365}$.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 1\n",
    "\n",
    "Write a function that takes $n$ as the argument and returns the analytical probability for $p(n) = 1-\\bar{p}(n)$ using the formua above. The permutation function `perm` is available in `scipy.special`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import packages used in HW\n",
    "\n",
    "from scipy.special import perm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "from scipy.stats import pearsonr\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas_datareader as pdr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def p_bar_n(n):\n",
    "    prob = 1 - perm(365,n)/(365**n)\n",
    "    return prob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test your function by evaluating it at $n=23$. Do you get the same number reported in the Wikipedia article (right under [equation 2](https://en.wikipedia.org/wiki/Birthday_problem#math_2))?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_bar_n(23)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a `np.array` with the probabilities for all values of $n$ from 1 to 100. Call it \"probs\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probs = np.fromiter((p_bar_n(n) for n in range(1,101)),float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the code below to plot these probabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "\n",
    "plt.plot(probs);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll use simulations to see if we can get the same results without using any math. Start by writing a function that takes arguments `n` and `num_trials` and estimates the probability through simulation. \n",
    "\n",
    "Each simulation should:\n",
    "* Create a \"room\" with `n` people. What data structure will work best here? (list, dictionary, numpy array, pandas Series, etc.)\n",
    "* Assign each person a random birthday. Practically speaking, you would probably just give them a number from 1 to 365.\n",
    "* Check if any two people have the same birthday, and add one to a counter to keep track of how many simulations have met this condition\n",
    "\n",
    "Call your function `birthday_sim`. It function should return the estimated probability (that is, the number of simulated rooms with a match, divided by the total number of rooms). A good default value for `num_trials` is 5000."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def birthday_sim(n,num_trials = 5000):\n",
    "    counter = 0\n",
    "    for i in range(0,num_trials):\n",
    "        simulation = np.unique(np.random.randint(1,366,n))\n",
    "        if len(simulation) < n:\n",
    "            counter += 1\n",
    "        else:\n",
    "            continue\n",
    "            \n",
    "    return counter / num_trials"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate your function at $n=23$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "birthday_sim(23)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate your function at $n=23$ using 100,000 trials."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "birthday_sim(23, num_trials = 100000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the code below to draw a picture of the probabilities from the simulation. How similar is it to the graph generated from analytical probabilities earlier?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try a bunch of inputs at once and store in a list\n",
    "# To keep time manageable, don't do too many trials\n",
    "probs = [birthday_sim(n, num_trials=5000) for n in range(1,50)]\n",
    "\n",
    "# Plot\n",
    "index = range(1,len(probs)+1)\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.bar(index, probs, alpha=0.5)\n",
    "plt.title('Probability of Two People Having Same Birthday', fontsize=14)\n",
    "plt.xlabel('Number of People in Room', fontsize=12)\n",
    "plt.ylabel('Probability', fontsize=12);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The graph above is extremely similar to the graph generated from the analytical probabilities in question 1.\n",
    "# Also, when ran to include 100 people in the room, the similarity remains. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2 — Sentiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 3\n",
    "\n",
    "Use the AAII survey data we used in class to see whether sentiment about future returns is more closely related to future returns or past returns. In particular, compare the correlations between the bull/bear spread and future 6-mo or 1-yr returns with the spread measure and *past* returns over the same horizons. Comment on what you learn from your findings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent = pd.read_excel('http://www.aaii.com/files/surveys/sentiment.xls',\n",
    "                     skiprows=7, header=None, usecols='A:D,M',\n",
    "                     names = ['Date', 'Bullish', 'Neutral', 'Bearish', 'sp500'])\n",
    "\n",
    "pd.to_datetime(sent['Date'], errors='coerce')\n",
    "sent['Date'] = pd.to_datetime(sent['Date'], errors='coerce')\n",
    "sent = sent.dropna(subset=['Date'])\n",
    "sent = sent.set_index('Date')\n",
    "sent['spread'] = sent['Bullish'] / sent['Bearish']\n",
    "sent['p6mret'] = sent['sp500'] / sent['sp500'].shift(26) -1\n",
    "sent['f6mret'] = sent['sp500'].shift(-26) / sent['sp500'] -1\n",
    "\n",
    "sent = sent.dropna()\n",
    "\n",
    "pearsonr(sent['spread'], sent['f6mret'])\n",
    "sent['spread_sm'] = sent['spread'].ewm(alpha=.5).mean()\n",
    "pearsonr(sent['spread_sm'], sent['f6mret'])\n",
    "df = sent.loc['2001':]\n",
    "for v in ['Bullish', 'Neutral', 'Bearish', 'spread']:\n",
    "    y, z = pearsonr(df[v].ewm(alpha=.25).mean(), df['p6mret'])\n",
    "    print('Correlation of {} and p6mret: {:.3f} ({:.2f})'.format(v, y, z) )\n",
    "    r, p = pearsonr(df[v].ewm(alpha=.25).mean(), df['f6mret'])\n",
    "    print('Correlation of {} and f6mret: {:.3f} ({:.2f})\\n'.format(v, r, p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Based on the outout above, we found that the sentiment data is primarily predicated\n",
    "# on past performance rather than future (analyzing 6-month performance trends).\n",
    "# Relatively spearking, the correlation between the bull-bear spread and past\n",
    "# 6-month returns is stronger than the spread and future returns. Also, interestingly,\n",
    "# there is a negative correlation between the spread and future returns. \n",
    "# Furthermore, the relative strength observation is also observed for bullish, neutral, and bearish."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 3 — Returns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Begin with a DataFrame of S&P 500 member firms. You constructed this in a previous assignment. For this part, all you need is ticker symbols."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "html = pd.read_html('https://en.wikipedia.org/wiki/List_of_S%26P_500_companies', header = 0)\n",
    "comps = html[0]['Symbol']\n",
    "comps = pd.DataFrame(comps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Question 4\n",
    "\n",
    "Select a random sample of 25 stocks. (Use a random seed so your results can be replicated.)\n",
    "\n",
    "Download historical price data using the pandas datareader for each stock. By default, the datareader gets data beginning in 2010, which is fine for our purposes. Here's an example of downloading prices for IBM."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Construct a `DataFrame` in which each column contains daily *returns* (not prices) for a different stock in your sample. That is, it should have 25 columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tickers = random.sample(list(set(comps['Symbol'])),25)\n",
    "data = pdr.get_data_yahoo(tickers)\n",
    "data = data.loc[:,['Adj Close']]\n",
    "returns = data['Adj Close'].pct_change()\n",
    "len(returns.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each stock, calculate the autocorrelation of returns. Note that the autocorrelation function is a method for `Series` but not `DataFrames`. You can apply it to every column using the `apply` function like this:\n",
    "\n",
    "`df.apply(lambda x: x.autocorr())`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How does the average autocorrelation compare to the autocorrelation of the S&P 500 index portfolio? (Ticker symbol: '^GSPC'). Try to explain any differences you observe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "autocorr = returns.apply(lambda x: x.autocorr())\n",
    "autocorr.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "itick = '^GSPC'\n",
    "idata = pdr.get_data_yahoo(itick)\n",
    "iret = idata['Adj Close'].pct_change()\n",
    "iframe = pd.DataFrame({itick:iret})\n",
    "iframe = iframe.fillna(0)\n",
    "iframe[itick].autocorr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Based on the output, the S&P has a relatively stronger negative autocorrelation (absolute difference \n",
    "# depends on sample). Also, it is important to note that the S&P 500 index is market cap weighted with \n",
    "# 500 stocks, whereas the sample used is not adjusted for market cap and uses only 25 randomly chosen stocks \n",
    "# from the index. Therefore, we conclude that the difference in autocorrelation (index v. sample), as well\n",
    "# as the large relative standard deviation for the sample values, is primarily due to the reasons previously \n",
    "# stated."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
